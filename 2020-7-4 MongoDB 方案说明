

消息队列



1.为什么通过消息队列进入的数据，需要先写入到MongoDB：

回答：好处很多，也很必要。
首先，数据最终会一批一批而不是一条一条写到数据库，这样很高效。原理和IF、Ladon的设计一样的。
其次，消息队列中的数据只能取一次，将数据写入Mongo，即使后续业务处理过程发现错误，也能找到原始数据查明原因。否则，只能找上游。
最后，Mongo的写入性能远好于关系型数据库。


2.为什么 FIle 过来的数据，不需要先写入Mongo：

回答：因为从一个文件就代表了一批数据，而且事后需要确认原始数据时，我们只要找到原始文件就可以了，所以不需要再写入 Mongo。


3.从消息队列过来的数据，需要先存一份，那为什么不能使用数据库，非要使用 MongoDB

回答：不能使用数据库替换 MongoDB。
最主要的原因是处理方便，因为消息队列、MongoDB、以及IF集成的数据映射工具（Kettle），他们共同支持一种数据格式，但采用这种数据格式时，三者可以无缝使用，中间不需额外处理。

下面举个例子，当我们有个消息队列过来的业务数据需要处理：

采用 MongoDB，业务开发人员在IF界登记下消息队列的地址，然后使用 Kettle 工具画一下数据流程，开发过程就完成了。
（主要因为消息队列的数据可以直接写入到MongoDB，而 Kettle 也能识别 MongoDB 的数据格式，从而节省了好多工作）

采用数据库，业务开发人员在IF界登记下消息队列的地址，然后根据消息体设计数据表结构，创建数据表。编写业务实现代码，将数据写入到数据表。然后使用 Kettle 画数据流程。
除此之外，开发人员还需要考虑数据表的维护、历史数据处理以及数据量过大对写入的影响，还有多久时间需要重新清理一次等问题。
而数据库写入速度要慢于 MongoDB，会让整个处理过程边长。

小结，从消息队列的业务处理角度来说，无论是几个工具之间的契合度、写入效率还是业务后续开发的工作量来说，MongoDB 方案都优于数据库。
最初，我们的确存在消息队列的业务需求，这个技术选型并没有问题，只是到 PH1 阶段结束之后这部分业务需求意外取消才受到了影响。



文件处理



目前流程处理中，异常数据会写入到 MongoDB 而不是Postgresql，原因如下：

1.需要利用他的高效写入性能，来减少数据流程处理中的停留时间。
目前，读取文件数据，先识别数据格式，然后验证数据，如果发现数据有问题会跳过处理下一条。但被跳过的数据，也需要记录下来（包括验证不通过的原因、所属文件、在文件中出现的位置、什么时间产生、由哪个节点的哪个流程处理的）。
实际上，谁也不能保证待处理数据中不会出现错误记录，而处理异常记录时流程会短暂停止，从性能上考虑，我希望这个过程能够尽量短，尽量不要影响整个流程的处理时间。

2.我们需要根据每日处理的文件，从存储的角度来评估每日产生的异常数据纪录。
单文件中出现错误的记录数量和频率都不会太高，但是随着后续业务扩展，我们每日处理的文件持续增加，异常记录也会相对增长。另外，异常记录需要保存多久，业务人员应对异常数据后，异常数据即使清除，还是为了减少风险保留一段时间，或者作为后续评价数据处理流程的分析评价使用。
如果数据库中的异常数据记录保留过多，也会拖慢数据处理速度。

小结，IF 的异常数据业务上很特殊，只产生一次并且后续不会修改。考虑到这个过程最大的影响是异常数据写入速度，如果同时让我在数据库和 MongoDB 中做选择，我肯定会考虑后者。



产品化



1.IF 在 BO 项目中的构成：
4种服务（监控服务、执行服务、配置服务、配置前台）
5种中间件（数据库、Redis集群、RocketMQ集群、MongoDB、Nginx）
以上中间件，除了MongoDB是IF提出的，其余都是现有BO环境提供的。

2.IF 裁减后的构成：
实际上，IF 可以根据业务需要对这个清单进行裁减，以下为裁减后的最小集合：
2种服务（IF后台服务，配置前台）
1种中间件（数据库）
当然，如果不需要监控，或者希望把监控接入到自己的系统，甚至可以把配置前台也去除，只剩下一个 IF 后台服务。

3.IF 裁减后的影响：
裁减后，性能、高可用，以及容灾能力等都会不同程度的受到影响。
举个例子：
Redis 集群裁减成 Ehcache，后者无需部署，直接集成在IF中，但是会占用IF内存，相当于IF可用内存变小，性能下降。
RocketMQ 集群裁减成 BlockingQueue，无需部署，这是一种数据结构，同样占用IF内存。而且替换后，IF不再具有分布式任务调度的能力。
MongoDB 裁减成 Postgres，减少一个了中间件，变成只支持文件处理一种模式，不再具有支持消息队列的能力。同时，异常数据记录切换为数据库记录。

实际上，我们可以根据业务需要来决定裁减的内容。可以出一份清单，根据相应的需求，进行配置。
当然，最低限度的主备模式、以及自动容灾还是支持的，挂掉一个节点仍然可以使用，只是不能调度，任务可能会受到处理性能影响，发生堆积。

4.IF 裁减改动大么：
首先，主要的处理流程不会受到太多影响。（对监听、任务调度、批处理框架、数据映射框架、流程监控，核心模块影响都不大，有些基本没有）
其次，我们目前最大的问题是目前为了应对BO，没有时间投入对 IF 的产品化过程。而以上可裁减内容，其实都可作为配置项，根据需要开启和关闭，并不一定限制部署IF一定需要哪些中间件。而将以上可裁减项目配置化的过程并不会占用很多的开发时间，但测试及业务验证会花工夫。当然，配置化过程也可根据业务优先级调整，并没有一定的先后顺序。

小结，适合 BO 的部署结构并不一定适合其他项目，而裁减过程相当于为业务量身定制套餐。而目前的 IF 还是一个项目，只有历练过多个项目之后，才能成为一个成熟的产品。
还有，IF 和 ladon 的定位是不一样的。
ladon 是一套设计优良的分布式任务调度插件，业务开发人员仍然需要在指导下编写具体的业务代码。
IF 定位是一套独立的服务，可以简化开发流程和工作，大部分场景下，甚至可以不用编写代码。




部署运维


MongoDB 在生产环境由 DBA 托管，不需要 BO 运维。
另外，内存占用的问题，是根据实际业务数据量来的。IF 和 MongoDB在部署上用服务器隔离，不会受到影响。



最后，考虑适合 BO 的方案



我充分理解部长基于数据量对IF部署结构的考虑，如果说目前我们每日待处理的文件以及单文件数据量，预计凭借现有 Postgres 的写入速度和存储就足可满足要求，要是之后不满足或者未来有需要再作扩展，这是可行的。
如果这方面确认的话，我建议先把 MongoDB 做成配置化，保留 MongoDB 这个选项。当后续每日数据读写达到一定量级需要性能调优或者我们有了消息队列的业务需求，到时配置就可以了，不需要修改代码。
如果部长考虑更多的是后续项目能复用 IF，我建议可以在之后开启配置化过程，我会列出一份详细的配置套餐，根据需要和优先级作计划。























